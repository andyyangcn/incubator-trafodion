////
/**
* @@@ START COPYRIGHT @@@
*
* Licensed to the Apache Software Foundation (ASF) under one
* or more contributor license agreements.  See the NOTICE file
* distributed with this work for additional information
* regarding copyright ownership.  The ASF licenses this file
* to you under the Apache License, Version 2.0 (the
* "License"); you may not use this file except in compliance
* with the License.  You may obtain a copy of the License at
*
*   http://www.apache.org/licenses/LICENSE-2.0
*
* Unless required by applicable law or agreed to in writing,
* software distributed under the License is distributed on an
* "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
* KIND, either express or implied.  See the License for the
* specific language governing permissions and limitations
* under the License.
*
* @@@ END COPYRIGHT @@@
*/
////
[[quickstart]]
= Quick Start

This chapter provides a quick start for how to use the command-line {project-name} Installer to install {project-name}. 
*If you prefer to intall on HDP distribution using Ambari, refer to the <<install-ambari,Ambari Install>> section.*

You need the following before using the information herein:

* A supported and running Hadoop enviroment with HDFS, HBase, and Hive. Refer to the 
http://trafodion.apache.org/release-notes.html[Release Notes] for information about supported versions.
* A user ID with passwordless SSH among all the nodes in the cluster. This user ID must have sudo access.

NOTE: The {project-name} Installer modifies and restarts your Hadoop environment.

== Download Binaries
You download the {project-name} binaries from the {project-name} {download-url}[Download] page. 
Download the following packages:

* {project-name} Installer (if planning to use the {project-name} Installer)
* {project-name} Server

NOTE: You can download and install the {project-name} Clients once you've installed and activated {project-name}. Refer to the
{docs-url}/client_install/index.html[{project-name} Client Install Guide] for instructions.

*Example*

Download the Trafodion Installer and Server binaries:
```
$ mkdir $HOME/trafodion-download
$ cd $HOME/trafodion-download
$ # Download the Trafodion Installer binaries
$ wget http://apache.cs.utah.edu/incubator/trafodion/trafodion-2.1.0.incubating/apache-trafodion-pyinstaller-2.1.0-incubating.tar.gz
Resolving http://apache.cs.utah.edu... 192.168.1.56
Connecting to http://apache.cs.utah.edu|192.168.1.56|:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 68813 (67K) [application/x-gzip]
Saving to: "apache-trafodion-pyinstaller-2.1.0-incubating.tar.gz"

100%[=====================================================================================================================>] 68,813       124K/s   in 0.5s

2016-02-14 04:19:42 (124 KB/s) - "apache-trafodion-pyinstaller-2.1.0-incubating.tar.gz" saved [68813/68813]

$ wget http://apache.cs.utah.edu/incubator/trafodion/trafodion-2.1.0.incubating/apache-trafodion_server-2.1.0-RH-x86_64-incubating.tar.gz
Resolving http://apache.cs.utah.edu... 192.168.1.56
Connecting to http://apache.cs.utah.edu|192.168.1.56|:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 214508243 (205M) [application/x-gzip]
Saving to: "apache-trafodion_server-2.1.0-RH-x86_64-incubating.tar.gz"

100%[=====================================================================================================================>] 214,508,243 3.90M/s   in 55s

2016-02-14 04:22:14 (3.72 MB/s) - "apache-trafodion_server-2.1.0-RH-x86_64-incubating.tar.gz" saved [214508243/214508243]

$ ls -l
-rw-rw-r--. 1 centos centos     74237 Feb 13 14:53 apache-trafodion_pyinstaller-2.1.0-incubating.tar.gz
-rw-rw-r--. 1 centos centos 183114066 Feb 10 22:34 apache-trafodion_server-2.1.0-RH-x86_64-incubating.tar.gz
$
```

[[quickstart-unpack-installer]]
== Unpack Installer and Server package

The first step in the installation process is to unpack the {project-name} Installer tar file.
{project-name} server package tar file can be auto detected by installer if put it in installer's folder.

*Example*

```
$ mkdir $HOME/trafodion-installer
$ cd $HOME/trafodion-downloads
$ tar -zxf apache-trafodion-pyinstaller-2.1.0-incubating.tar.gz -C $HOME/trafodion-installer
$ cp -f apache-trafodion_server-2.1.0-RH-x86_64-incubating.tar.gz $HOME/trafodion-installer
$ ls $HOME/trafodion-installer/python-installer
apache-trafodion_server-2.1.0-RH-x86_64-incubating.tar.gz  db_install.py    DISCLAIMER    LICENSE  prettytable.py  scripts
configs                                                    db_uninstall.py  discovery.py  NOTICE   README.md
$
```

[[quickstart-collect-information]]
== Collect Information

Collect/decide the following information:


=== Java Location

Java location can be automatically detected by installer. You need to provide the java location only if installer cannot detect it.

How to detect java location manually:

1. Login to trafodion' node
2. Use `ps -ef | grep java | grep hadoop | grep hbase` to determine what version HBase is running.

*Example*

```
ps -ef | grep java | grep hadoop | grep hbase
hbase     17302  17288  1 20:35 ?        00:00:10 /usr/jdk64/jdk1.7.0_67/bin/java -Dproc_master -XX:OnOutOfMemoryError=kill -9 %p -Dhdp.version=2.3.6.0-3796 -XX:+UseConcMarkSweepGC -XX:ErrorFile=/var/log/hbase/hs_err_pid%p.log -Djava.io.tmpdir=/tmp -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -Xloggc:/var/log/hbase/gc.log-201606302035 -Xmx1024m -XX:PermSize=128m -XX:MaxPermSize=128m -Dhbase.log.dir=/var/log/hbase -Dhbase.log.file=hbase-hbase-master-ip-172-31-56-238.log -Dhbase.home.dir=/usr/hdp/current/hbase-master/bin/.. -Dhbase.id.str=hbase -Dhbase.root.logger=INFO,RFA -Djava.library.path=:/usr/hdp/2.3.6.0-3796/hadoop/lib/native/Linux-amd64-64:/usr/hdp/2.3.6.0-3796/hadoop/lib/native -Dhbase.security.logger=INFO,RFAS org.apache.hadoop.hbase.master.HMaster start
```

The Java location is: `/usr/jdk64/jdk1.7.0_67`

<<<
=== Data Nodes

{project-name} is installed on all data nodes in your Hadoop cluster. Data nodes can be automatically detected by installer while installing on a HDP/CDH cluster.

You need to record hostname for each node when you install {project-name} on Apache Hadoop.
For example, refer to `/etc/hosts`.

*Example*

```
$ cat /etc/hosts
127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6

172.31.56.238	      node-1.internal node-1
172.31.61.110	      node-2.internal node-2
```

Record the node names in a comma-separated list `node-1, node-2` or in regular expression mode `node-[1-2]`

=== Distribution Manager URL

The Installer interacts with the Distribution Manager (for example, Apache Ambari or Cloudera Manager) to modify the
Hadoop configuration.

*Example*

Apache Ambari URL

```
http://myhost.com:8080
```

<<<
[[quickstart-run-installer]]
== Run Installer

You run the Installer once you've collected the base information as described in
<<quickstart-collect-information, Collect Information>> above.

Please refer to <<install-guided-install, Guided Install>> for the *example* of installing {project-name} on a two-node Cloudera Hadoop cluster.
